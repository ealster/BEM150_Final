BEM150 Final Project
========================================================
Eli Alster  
Vansh Kumar  
Angad Rekhi  

     We analyzed the NYC traffic data set. In order to simplify analysis, we only considered the 2013 data so the data set would be fixed.
  
```{r LoadData, echo=FALSE, cache=TRUE}
     library("plyr")
     library("hexbin")
     install.packages('e1071', dependencies = TRUE)
     library(e1071)
     df = read.csv("collisions.csv", header = TRUE, sep="\t")
     df = subset(df, year != 2013)
     df$lat = as.numeric(as.character(df$lat))
     df[is.na(df)] = 0
```

```{r fig.width=7, fig.height=6}
     scooter_accidents = subset(df, scooter == TRUE)
     plot(scooter_accidents$lon, scooter_accidents$lat)
```
Plot of bicycle accidents.

```{r}
     df_in = subset(df, lat < 44)
     bin = hexbin(df_in$lon, df_in$lat, xbi=75)
     plot(bin, main="2013 Traffic Deaths in NY by Location", xlab="Longitude", ylab="")
     mtext(text = "Latitude", side=2, line=3)
```
Accident frequency map!

Histogram of reason for accident vs total people killed.

```{r Reasons_of_Death}
     reasons = df[,39:68]

     mat = matrix(nrow=4, ncol=ncol(reasons))
     for ( r in 1:ncol(reasons) ) 
     {
          reason = names(reasons)[[r]]
          reason_row = subset(df, df[[reason]]==TRUE)
          ped = sum(reason_row[,"pedestr_killed"])
          pass = sum(reason_row[,"passengers_killed"])
          motor = sum(reason_row[,"motorists_killed"])
          cycle = sum(reason_row[,"cyclists_killed"])
          
          mat[,r] = c(ped, pass, motor, cycle)
     }

     par(mar=c(4,10,2,1)) # increase margins on plot 
     par(las=2)          # align accident names horizontally
     colors=c("blue","green","red","black")
     barplot(mat, horiz=TRUE, names.arg=colnames(reasons), col=colors, main="2013 NYC Deaths by Kind of Accident", xlab="Number of Deaths", xlim=c(0,40), cex.names=0.5)
     legend(x=25,y=25,fill=colors,legend=c("Pedestrians","Passengers","Motorists","Cyclists"))
 
```

``` {r Data_Munging}

# Notes:
# x = classification matrix
# y = factors for each type
# scale = FALSE if just factors
# 39:68 reason, lon, lat, 
dataf = data.frame(df$lon, df$lat, df[,39:68], df[,22:38])
model = svm(dataf, y = as.factor(df$total_killed), kernel = "linear", cost = .1, 
     method = "C-classification", scale = FALSE)

# # Testing
# spam_test = read.csv('Spam_TestSet.csv')
# answers = spam_test[,1]
# predictions = predict(model, spam_test[,-1], decision.values = TRUE)
# 
# # See how many were correct
# trials = nrow(spam_test)
# correct_amt = sum(answers == predictions)
# correct_pct = correct_amt / trials
# 
# # Calculated most important words
# var_weights = t(model[["coefs"]]) %*% model[["SV"]]
# vocab_list = read.csv('vocab.txt', sep="\t", header = FALSE)

```

